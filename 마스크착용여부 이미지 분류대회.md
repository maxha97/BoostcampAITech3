# 마스크 착용여부 이미지 분류 대회(Level1)


## 대회 참여에서 설정한 목표
- 베이스라인 코드 이해를 통해, 어떻게 image classification 태스크가 진행되는지를 알고자 하였다.
- 기존에 사용해보지 못한, Wandb, Tensorboard를 활용하여 성능을 비교하고, 비대면 협업의 효율성을 극대화해고자 하였다.
- 다양한 Loss에 대한 원리를 이해하고, 사용을 통해 학습에 대한 경향성을 파악하여 가장 적합한 학습방안을 제시하고자 하였다.
- Resnet18을 시작으로, 다양한 SOTA 모델을 활용하여 모델 간의 성능을 확인하고 구동의 효율성을 확인하고자 하였습니다.




## 진행하면서 학습하고 시도해본 것들

### 1) 다양한 모델 적용
- **Efficientnet 모델(파라미터 수 및 모델의 크기에 따라 b0~b7버전이 존재)**
![image](https://user-images.githubusercontent.com/53209003/156936117-980d991b-0769-4dcd-8630-e606e8c75b3e.png)   
 상대적으로 동일한 성능을 가진 Resnet 모델들 대비, 훨씬 더 적은 파라미터 수로 동일한 성능을 달성하였음. 이를 통해, 20202년 기준 더 적은 파라미터 수를 가짐에도 불구하고 당시의 높은 성능을 자랑하는 AmoebaNet, Inception, ResNet, DenseNet 모델 등을 따돌리면서 SOTA 성능을 달성하였음.   
 ![image](https://user-images.githubusercontent.com/53209003/156936269-2b789b64-cc7e-4335-a065-cedc44206ee8.png)   
이는 기존의 네트워크 width(모델 채널 수), depth(모델 네트워크 수), resolution(입력 이미지 해상도)를 늘릴 경우 성능이 점차적으로 증가하고 수렴함을 확인할 수 있음. 이 값들이 증가하되, 이 3가지 지표가 무작정 늘리는 것이 좋은 것이 아니라, 서로 간의 관계를 기반으로 최적의 증가값을 찾아주는 것이 비전 모델의 성능에 중요한 영향을 미친다는 것을 확인후 실행에 옮긴 모델. 
 

### 2) 다양한 Loss 학습 및 적용
- **CrossEntropy Loss**   
![image](https://user-images.githubusercontent.com/53209003/156934799-f7ad4c0c-5f38-46af-9342-16a008444f26.png)     
엔트로피 개념이 손실(loss)함수에서 사용된 사례로 볼 수 있음. 만약 이진분류 태스크가 아닌 N개의 라벨 중 하나로 분류하는 태스크일 때, 입력 데이터가 모델을 통과할 경우 소프트맥스 함수에 의해 각 클래스에 속할 확률이 계산됨(Q(x)). 실제 값의 경우, 정답인 클래스만 확률이 1이고, 나머지는 모두 0인 확률분포에 해당(P(x)). 이 두 확률분포의 차이를 Cross Entropy 수식 형태로 표현하여 계산할 수 있음. Cross Entropy를 줄이기 위한 파라미터를 구하는 것이 negative log likelohood를 최소화하는 파라미터를 구하는 것과 동일

- **Focal Loss**   
![image](https://user-images.githubusercontent.com/53209003/156935353-b9c58874-17bd-4cf9-b437-147c4f6d568a.png)    
기존의 Cross Entropy의 경우 분류태스크에서 분류할 라벨별로 데이터가 균등한 비율로 존재할 경우 학습에 문제가 없음. 하지만, 라벨 비율이 불균형한 데이터에 있어서는 학습에 문제를 일으킬 수 있음. 이는, 데이터 라벨 비중이 높아 샘플 비중이 높은 Easy Negative 샘플에 대해 중점적으로 학습하게됨. Focal Loss 기존의 Cross Entropy에 가중치를 곱함으로써, Easy Negative 샘플에 대한 학습에 중점적으로 뒀던 학습과정에 패널티를 부여할 수 있음. 이에 따라, 데이터 라벨 비중이 낮은 Hard Negative 샘플에 대해서도 추가적으로 학습할 수 있는 구조를 취하여 불균형 데이터에 효과적임을 알 수 있었음.

- **F1 Loss**   
F1 score가 정밀도(Precision, Positive로 예측한 것중 실제 Positive 비율)와 재현율(Recall, 실제 Positive인 것 중 Positive로 예측한 비율)을 함께 고려한 점수 metric인만큼, F1 Loss 역시 
클래스 별로 정밀도 및 재현율을 함께 고려했을 것으로 생각되나, 좀 더 학습이 필요한 상황

### 3)WanDB 사용을 통한 효율적인 모델 비교 및 하이퍼 파라미터 튜닝 
![image](https://user-images.githubusercontent.com/53209003/156936616-585a1e1d-2010-4ec2-80c7-97c39c9d6f71.png)    
Wandb Teams를 구성하여, 실시간으로 각 팀원들이 실행 중인 모델들의 Train,Validation에서의 성능지표(acc, f1-macro, loss)들을 에폭을 기준으로 비교해볼 수 있었음. 이릍 통해, 비대면임에도 불구하고 함께 효율적으로 모델 비교 및 선정이 가능하였음. 이외에도, Loss, Optimizer, Learningrate 등에 따른 하이퍼 파라미터 튜닝에 있어서도 효율적으로 최적 파라미터를 찾을 수 있었음. 하지만, 제출성능이 Validation 성능과는 차이가 있어, 100% 완벽한 판단을 내리기에는 어려움이 있었음. 




## 추후 시도해보면 좋은 것들
-	**Nivida APEX – AMP**   
엔비디아에서 제공중이며, 현재는 파이토치 기본 라이브러리로 탑재된 APEX 패키지는  AMP(Automatic Mixed Precision) 기능을 제공하고 있음. AMP 기능을 활용할 경우 FP16연산과 FP32 연산을 섞어 학습을 진행할 수 있음. 이렇게 진행하게 될 경우, 학습 속도에 있어 향상이 있으며, 16bit를 혼용함에 따라 램사용량을 최적화할 수 있음. 이에 따라, 기존에는 네이버 V100 서버에서의 90기가램에서 설정하지 못한 배치사이즈를 시도해보거나, 더 많은 파라미터 수를 가진 모델(ex. Efficientnet_b7)을 시도해 봄으로써 성능 향상을 기대해볼 수 있을 것.

-	**Pytorch Lightning**   
파이토치의 하이레벨 언어로 모델학습 및 예측 과정에서 훨씬 가벼운 코드를 작성할 수 있도록 도와줌. 추후, 코드 작성에 소모되는 시간을 단축하기 위해 시도해보면 좋을 것으로 생각됨   
([파이토치] 머신러닝 Pytorch 모델의 성능을 극대화하는 7가지 팁!: https://bbdata.tistory.com/9)
