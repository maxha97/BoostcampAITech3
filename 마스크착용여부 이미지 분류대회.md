# 마스크 착용여부 이미지 분류 대회(Level1)

## 대회 설명
COVID-19의 확산으로 우리나라는 물론 전 세계 사람들은 경제적, 생산적인 활동에 많은 제약을 가지게 되었습니다. 우리나라는 COVID-19 확산 방지를 위해 사회적 거리 두기를 단계적으로 시행하는 등의 많은 노력을 하고 있습니다. 과거 높은 사망률을 가진 사스(SARS)나 에볼라(Ebola)와는 달리 COVID-19의 치사율은 오히려 비교적 낮은 편에 속합니다. 그럼에도 불구하고, 이렇게 오랜 기간 동안 우리를 괴롭히고 있는 근본적인 이유는 바로 COVID-19의 강력한 전염력 때문입니다.

감염자의 입, 호흡기로부터 나오는 비말, 침 등으로 인해 다른 사람에게 쉽게 전파가 될 수 있기 때문에 감염 확산 방지를 위해 무엇보다 중요한 것은 모든 사람이 마스크로 코와 입을 가려서 혹시 모를 감염자로부터의 전파 경로를 원천 차단하는 것입니다. 이를 위해 공공 장소에 있는 사람들은 반드시 마스크를 착용해야 할 필요가 있으며, 무엇 보다도 코와 입을 완전히 가릴 수 있도록 올바르게 착용하는 것이 중요합니다. 하지만 넓은 공공장소에서 모든 사람들의 올바른 마스크 착용 상태를 검사하기 위해서는 추가적인 인적자원이 필요할 것입니다.

따라서, 우리는 카메라로 비춰진 사람 얼굴 이미지 만으로 이 사람이 마스크를 쓰고 있는지, 쓰지 않았는지, 정확히 쓴 것이 맞는지 자동으로 가려낼 수 있는 시스템이 필요합니다. 이 시스템이 공공장소 입구에 갖춰져 있다면 적은 인적자원으로도 충분히 검사가 가능할 것입니다.



## 대회 참여에서 설정한 목표
- 베이스라인 코드 이해를 통해, 어떻게 image classification 태스크가 진행되는지를 알고자 하였다.
- 기존에 사용해보지 못한, Wandb, Tensorboard를 활용하여 성능을 비교하고, 비대면 협업의 효율성을 극대화해고자 하였다.
- 다양한 Loss에 대한 원리를 이해하고, 사용을 통해 학습에 대한 경향성을 파악하여 가장 적합한 학습방안을 제시하고자 하였다.
- Resnet18을 시작으로, 다양한 SOTA 모델을 활용하여 모델 간의 성능을 확인하고 구동의 효율성을 확인하고자 하였습니다.




## 진행하면서 학습하고 시도해본 것들

### 1) 다양한 모델 적용
- **Efficientnet 모델(파라미터 수 및 모델의 크기에 따라 b0~b7버전이 존재)**
![image](https://user-images.githubusercontent.com/53209003/156936117-980d991b-0769-4dcd-8630-e606e8c75b3e.png)   
 상대적으로 동일한 성능을 가진 Resnet 모델들 대비, 훨씬 더 적은 파라미터 수로 동일한 성능을 달성하였음. 이를 통해, 20202년 기준 더 적은 파라미터 수를 가짐에도 불구하고 당시의 높은 성능을 자랑하는 AmoebaNet, Inception, ResNet, DenseNet 모델 등을 따돌리면서 SOTA 성능을 달성하였음.   
 ![image](https://user-images.githubusercontent.com/53209003/156936269-2b789b64-cc7e-4335-a065-cedc44206ee8.png)   
이는 기존의 네트워크 width(모델 채널 수), depth(모델 네트워크 수), resolution(입력 이미지 해상도)를 늘릴 경우 성능이 점차적으로 증가하고 수렴함을 확인할 수 있음. 이 값들이 증가하되, 이 3가지 지표가 무작정 늘리는 것이 좋은 것이 아니라, 서로 간의 관계를 기반으로 최적의 증가값을 찾아주는 것이 비전 모델의 성능에 중요한 영향을 미친다는 것을 확인후 실행에 옮긴 모델. 
 

### 2) 다양한 Loss 학습 및 적용
- **CrossEntropy Loss**   
![image](https://user-images.githubusercontent.com/53209003/156934799-f7ad4c0c-5f38-46af-9342-16a008444f26.png)     
엔트로피 개념이 손실(loss)함수에서 사용된 사례로 볼 수 있음. 만약 이진분류 태스크가 아닌 N개의 라벨 중 하나로 분류하는 태스크일 때, 입력 데이터가 모델을 통과할 경우 소프트맥스 함수에 의해 각 클래스에 속할 확률이 계산됨(Q(x)). 실제 값의 경우, 정답인 클래스만 확률이 1이고, 나머지는 모두 0인 확률분포에 해당(P(x)). 이 두 확률분포의 차이를 Cross Entropy 수식 형태로 표현하여 계산할 수 있음. Cross Entropy를 줄이기 위한 파라미터를 구하는 것이 negative log likelohood를 최소화하는 파라미터를 구하는 것과 동일

- **Focal Loss**   
![image](https://user-images.githubusercontent.com/53209003/156935353-b9c58874-17bd-4cf9-b437-147c4f6d568a.png)    
기존의 Cross Entropy의 경우 분류태스크에서 분류할 라벨별로 데이터가 균등한 비율로 존재할 경우 학습에 문제가 없음. 하지만, 라벨 비율이 불균형한 데이터에 있어서는 학습에 문제를 일으킬 수 있음. 이는, 데이터 라벨 비중이 높아 샘플 비중이 높은 Easy Negative 샘플에 대해 중점적으로 학습하게됨. Focal Loss 기존의 Cross Entropy에 가중치를 곱함으로써, Easy Negative 샘플에 대한 학습에 중점적으로 뒀던 학습과정에 패널티를 부여할 수 있음. 이에 따라, 데이터 라벨 비중이 낮은 Hard Negative 샘플에 대해서도 추가적으로 학습할 수 있는 구조를 취하여 불균형 데이터에 효과적임을 알 수 있었음.

- **F1 Loss**   
F1 score가 정밀도(Precision, Positive로 예측한 것중 실제 Positive 비율)와 재현율(Recall, 실제 Positive인 것 중 Positive로 예측한 비율)을 함께 고려한 점수 metric인만큼, F1 Loss 역시 
클래스 별로 정밀도 및 재현율을 함께 고려했을 것으로 생각되나, 좀 더 학습이 필요한 상황

### 3)WanDB 사용을 통한 효율적인 모델 비교 및 하이퍼 파라미터 튜닝 
![image](https://user-images.githubusercontent.com/53209003/156936616-585a1e1d-2010-4ec2-80c7-97c39c9d6f71.png)    
Wandb Teams를 구성하여, 실시간으로 각 팀원들이 실행 중인 모델들의 Train,Validation에서의 성능지표(acc, f1-macro, loss)들을 에폭을 기준으로 비교해볼 수 있었음. 이릍 통해, 비대면임에도 불구하고 함께 효율적으로 모델 비교 및 선정이 가능하였음. 이외에도, Loss, Optimizer, Learningrate 등에 따른 하이퍼 파라미터 튜닝에 있어서도 효율적으로 최적 파라미터를 찾을 수 있었음. 하지만, 제출성능이 Validation 성능과는 차이가 있어, 100% 완벽한 판단을 내리기에는 어려움이 있어 보조적인 판단 지표로 활용하는 것이 적절해보임




## 추후 시도해보면 좋은 것들
-	**Nivida APEX – AMP**   
엔비디아에서 제공중이며, 현재는 파이토치 기본 라이브러리로 탑재된 APEX 패키지는  AMP(Automatic Mixed Precision) 기능을 제공하고 있음. AMP 기능을 활용할 경우 FP16연산과 FP32 연산을 섞어 학습을 진행할 수 있음. 이렇게 진행하게 될 경우, 학습 속도에 있어 향상이 있으며, 16bit를 혼용함에 따라 램사용량을 최적화할 수 있음. 이에 따라, 기존에는 네이버 V100 서버에서의 90기가램에서 설정하지 못한 배치사이즈를 시도해보거나, 더 많은 파라미터 수를 가진 모델(ex. Efficientnet_b7)을 시도해 봄으로써 성능 향상을 기대해볼 수 있을 것.

-	**Pytorch Lightning**   
파이토치의 하이레벨 언어로 모델학습 및 예측 과정에서 훨씬 가벼운 코드를 작성할 수 있도록 도와줌. 추후, 코드 작성에 소모되는 시간을 단축하기 위해 시도해보면 좋을 것으로 생각됨   
([파이토치] 머신러닝 Pytorch 모델의 성능을 극대화하는 7가지 팁!: https://bbdata.tistory.com/9)
